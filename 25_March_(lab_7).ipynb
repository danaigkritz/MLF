{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danaigkritz/MLF/blob/main/25_March_(lab_7).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9457fdc4-1690-4c41-8e88-1597fc2a687c",
      "metadata": {
        "id": "9457fdc4-1690-4c41-8e88-1597fc2a687c"
      },
      "source": [
        " # MKA-MLF, Lab_07 Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e81ae9-825c-4132-97e6-7d19b1dcfd82",
      "metadata": {
        "id": "94e81ae9-825c-4132-97e6-7d19b1dcfd82"
      },
      "source": [
        "## Exercise - XOR Gate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fca4d43-ab0e-44d0-9279-9c38d757ab50",
      "metadata": {
        "id": "1fca4d43-ab0e-44d0-9279-9c38d757ab50"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ffa6be62-ed89-4801-b297-f1a1211ce297",
      "metadata": {
        "id": "ffa6be62-ed89-4801-b297-f1a1211ce297"
      },
      "source": [
        "## Exercise - Hand-written digits recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89808395-7ffe-4df1-91e5-f31ce090b932",
      "metadata": {
        "id": "89808395-7ffe-4df1-91e5-f31ce090b932"
      },
      "source": [
        "Create CNN which will process and recognize handwritten digits. For this purposes please use the MNIST database (Modified National Institute of Standards and Technology database) which is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
        "\n",
        "The datasample of the MNIST datasets can be see in the following picture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b6e2b8-73da-4476-b47d-2f4aafead049",
      "metadata": {
        "id": "87b6e2b8-73da-4476-b47d-2f4aafead049"
      },
      "source": [
        "![mnist_data_sample.png](attachment:eb3e0d6a-ccb0-499d-9847-ecbc554dbce0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c65f181-d971-4f0e-ba63-17c242a65d6c",
      "metadata": {
        "id": "0c65f181-d971-4f0e-ba63-17c242a65d6c"
      },
      "source": [
        "### Task description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b6b04cf-eeec-404a-824b-f9aa1d3b7d7a",
      "metadata": {
        "id": "1b6b04cf-eeec-404a-824b-f9aa1d3b7d7a"
      },
      "source": [
        "In the terms of machine learning, the Hand-written digits recognition can be threated as a multi-class classification problem. This is very important knowledge to structure our model in the correct way (Especially the output-layer, including the number of neurons and activations function and the overall loss function and classification metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b724de14-3931-4983-b443-7e0106d190dc",
      "metadata": {
        "id": "b724de14-3931-4983-b443-7e0106d190dc"
      },
      "source": [
        "### 0. Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffd9b11-f9c1-4b3f-8dd1-cbb18487a075",
      "metadata": {
        "id": "1ffd9b11-f9c1-4b3f-8dd1-cbb18487a075"
      },
      "source": [
        "Import the all necessary libraries, you can get inspired by the previous exercises. You can improst the libraries gradually, when do you progressing with the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f692dd4-0262-4e7a-b029-69d8280f14d2",
      "metadata": {
        "id": "1f692dd4-0262-4e7a-b029-69d8280f14d2"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "###################################\n",
        "# Write your own code here #\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "###################################\n",
        "font = {'weight' : 'bold',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4af957-fee1-4806-9d68-797d74c332df",
      "metadata": {
        "id": "9c4af957-fee1-4806-9d68-797d74c332df"
      },
      "source": [
        "### 1. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33cf2443-c2ed-4aaa-9b10-fa598a4fb6cb",
      "metadata": {
        "id": "33cf2443-c2ed-4aaa-9b10-fa598a4fb6cb"
      },
      "source": [
        "#### 1.1 Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd860d81-ab4d-48d2-a071-e0e8aec8000f",
      "metadata": {
        "id": "dd860d81-ab4d-48d2-a071-e0e8aec8000f"
      },
      "source": [
        "You can load the dataset using the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6f52dc-788b-4481-95f2-c4de31cae037",
      "metadata": {
        "id": "1b6f52dc-788b-4481-95f2-c4de31cae037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052a29ed-843c-415a-e9ac-173cddac397e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#check the shape of the data\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853727ee-5836-4345-84dd-b0135b33e6d3",
      "metadata": {
        "id": "853727ee-5836-4345-84dd-b0135b33e6d3"
      },
      "source": [
        "#### 1.2 Dataset examination"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e9f48e-3192-494a-9b0f-e2f66a7c286e",
      "metadata": {
        "id": "93e9f48e-3192-494a-9b0f-e2f66a7c286e"
      },
      "source": [
        "Using the following code, display random images,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522d7c5e-f50b-46d0-b79d-799d40ff2f1e",
      "metadata": {
        "id": "522d7c5e-f50b-46d0-b79d-799d40ff2f1e"
      },
      "outputs": [],
      "source": [
        "def display_random_images(x_data: np.array, y_data: np.array, count: int = 10) -> None:\n",
        "  index = np.array(len(x_data))\n",
        "  selected_ind = np.random.choice(index, count)\n",
        "\n",
        "  selected_img = x_data[selected_ind]\n",
        "  selected_labels = y_data[selected_ind]\n",
        "  concat_img = np.concatenate(selected_img, axis=1)\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.imshow(concat_img, cmap=\"gray\")\n",
        "\n",
        "  for id_label, label in enumerate(selected_labels):\n",
        "    plt.text(14 + 28*id_label, 28*(5/4), label)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452ea9c5-8438-4b10-8a0e-ef0e418ba5a0",
      "metadata": {
        "id": "452ea9c5-8438-4b10-8a0e-ef0e418ba5a0",
        "outputId": "04b9cdee-b513-4b7f-d63a-dbbe55d1b45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_random_images(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0e3651-3921-4485-bdae-3731afcf03a2",
      "metadata": {
        "id": "6c0e3651-3921-4485-bdae-3731afcf03a2"
      },
      "source": [
        "Examine the dataset. Answer for yourself the following questions:\n",
        "\n",
        "- What kind of data occurs in our dataset? ( integers)\n",
        "- How many data samples do we have in train and test datasets? (60.000)\n",
        "- How many colour channels does the input variable have? (1 channel)\n",
        "- What is the size of the input images? (28x28)\n",
        "- What is the necessary preprocessing of the input data X? (normalization/255)\n",
        "- How many classes do we have in target variable? (10)\n",
        "- What is the necessary preprocessing of target variable y? (convert in onehot enconding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08273dd4-05d0-4cd8-b989-eca8a4d1328a",
      "metadata": {
        "id": "08273dd4-05d0-4cd8-b989-eca8a4d1328a"
      },
      "source": [
        "#### 1.3 Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c16ee55-312f-4ee5-86cd-e09426e16e82",
      "metadata": {
        "id": "2c16ee55-312f-4ee5-86cd-e09426e16e82"
      },
      "source": [
        "Perform the necessary data preprocessing. The best way to preprocess the data would be one hot encoding for the target variable and normalization for the input variable (using min-max or z-score normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07697fb-0feb-4df1-8ed2-b7b20f0c015f",
      "metadata": {
        "id": "e07697fb-0feb-4df1-8ed2-b7b20f0c015f"
      },
      "outputs": [],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "#normalize the images to a range of 0 to 1\n",
        "X_train=X_train.astype('float32')/255\n",
        "X_test=X_test.astype('float32')/255\n",
        "\n",
        "#reshape the data to add a channel dimension (from CNN input)\n",
        "X_train=X_train.reshape(-1,28,28,1)\n",
        "X_test=X_test.reshape(-1,28,28,1)\n",
        "\n",
        "#one hot encode the labels\n",
        "y_train=to_categorical(y_train,10)\n",
        "y_test=to_categorical(y_test,10)\n",
        "\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20d5fef-cbca-48a2-844f-c9638f0b6bf9",
      "metadata": {
        "id": "d20d5fef-cbca-48a2-844f-c9638f0b6bf9"
      },
      "source": [
        "### 2. Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea554fcf-7acd-4453-b18d-b4982f6a10eb",
      "metadata": {
        "id": "ea554fcf-7acd-4453-b18d-b4982f6a10eb"
      },
      "source": [
        "In this section, your task will be to define the model architecture. The intial structure can be defined as follows:\n",
        "\n",
        "Input_layer -> Convolutional_layer(kernel_size=(3,3), no_channels=32) -> Maxpooling_layer(kernel_size=(2, 2)) -> Flatten_layer -> Dense_layer (num_classes)\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffd3896-079e-4758-9579-387f33af9691",
      "metadata": {
        "id": "0ffd3896-079e-4758-9579-387f33af9691"
      },
      "source": [
        "#### 2.1 Define the model structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77238bdf-ad74-4246-920d-a1dc28564306",
      "metadata": {
        "id": "77238bdf-ad74-4246-920d-a1dc28564306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82526edb-402f-47a8-9217-14b998f06249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "#convolutional layer with 32 filters, 3x3 kernel, relu activation\n",
        "model.add(Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "\n",
        "#maxpooling layer to reduce the spatial dimensions\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "#flatten layer to prepar fro the fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully conncted layer with 128 neurons and relu activation\n",
        "model.add(Dense(128,activation='relu'))\n",
        "\n",
        "#output layer with softmax activation for multiclass classification\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "###################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde4b3eb-90e1-4724-89df-0db1872560d4",
      "metadata": {
        "id": "fde4b3eb-90e1-4724-89df-0db1872560d4"
      },
      "source": [
        "#### 2.2 Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a467f8fb-8bfc-4cd4-9eee-820c1b9b5a52",
      "metadata": {
        "id": "a467f8fb-8bfc-4cd4-9eee-820c1b9b5a52"
      },
      "source": [
        "Build the model, use the relevant metrics, optimizer and loss function. While choosing the metrics and loss function, consider fact that we are are trying to solve the multiclass classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d1a924-9e2f-4ca2-b4d6-4724f51ae065",
      "metadata": {
        "id": "e6d1a924-9e2f-4ca2-b4d6-4724f51ae065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "572dbe0e-25cd-4cbe-d17a-22205a8ecf96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2704\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m346,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2704</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">346,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m347,800\u001b[0m (1.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,800</span> (1.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m347,800\u001b[0m (1.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,800</span> (1.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss = None\n",
        "optimizer = None\n",
        "metrics = None\n",
        "learning_rate = 0.0\n",
        "\n",
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "#compile the model\n",
        "model.compile(optimizer=Adam(),loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Assuming 10 classes\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))  # For 10 classes\n",
        "###################################\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f146b70f-2e8c-484f-abfd-6fc4a8b8177b",
      "metadata": {
        "id": "f146b70f-2e8c-484f-abfd-6fc4a8b8177b"
      },
      "source": [
        "### 3. Training stage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1de787-9e40-47e2-bc54-44ccd1864357",
      "metadata": {
        "id": "cb1de787-9e40-47e2-bc54-44ccd1864357"
      },
      "source": [
        "#### 3.1 Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b9c7722-aed7-4b2d-a292-572921f0734b",
      "metadata": {
        "id": "2b9c7722-aed7-4b2d-a292-572921f0734b"
      },
      "source": [
        "train your model, define the relevant hyperparameters (no. epochs, batch_size), use 20p of the training data for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f858566-601d-4873-ad02-a0635bd8f526",
      "metadata": {
        "id": "4f858566-601d-4873-ad02-a0635bd8f526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "c8257745-0df0-4d8e-a422-c7a6b0cc8f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10, 10)\n",
            "(10000, 10, 10)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10, 10), output.shape=(None, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2d0b65e07b01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#in this code i always get an error that i cannot fix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    651\u001b[0m         )\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10, 10), output.shape=(None, 10)"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "y_test = y_test.reshape(-1, 10)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "history=model.fit(X_train,y_train,epochs=10,batch_size=128,validation_data=(X_test,y_test),verbose=2)\n",
        "#in this code i always get an error that i cannot fix\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45651f2d-5cc4-4896-8edc-f58b50fed605",
      "metadata": {
        "id": "45651f2d-5cc4-4896-8edc-f58b50fed605"
      },
      "source": [
        "#### 3.1 Model Evaluation on validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4ea2f2-fcc8-4308-82f6-3dbd5857e989",
      "metadata": {
        "id": "eb4ea2f2-fcc8-4308-82f6-3dbd5857e989"
      },
      "source": [
        "Plot the development of the training and validation loss, and training and validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841d1e30-e448-4b53-b3fc-9b97863391bb",
      "metadata": {
        "id": "841d1e30-e448-4b53-b3fc-9b97863391bb"
      },
      "outputs": [],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22cd86fb-6b4c-4299-a077-fec0ab62464c",
      "metadata": {
        "id": "22cd86fb-6b4c-4299-a077-fec0ab62464c"
      },
      "source": [
        "### 4. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d93b7ad-3416-451d-8762-968f4cf1dd13",
      "metadata": {
        "id": "9d93b7ad-3416-451d-8762-968f4cf1dd13"
      },
      "source": [
        "Evaluate the model on the testing dataset using the relevant metrics. Use the confusion metrics as the one of the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8134b757-aca1-4a0d-a0d2-3a3d0daa8d38",
      "metadata": {
        "id": "8134b757-aca1-4a0d-a0d2-3a3d0daa8d38"
      },
      "outputs": [],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "#plot the confusion matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#list of class labels from MNIST 0-9\n",
        "labels=['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "#make predictions on the test data\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_classes=np.argmax(y_pred,axis=1) #convert predictions to class labels\n",
        "\n",
        "#get true glass lables\n",
        "y_true=np.argmax(y_test,axis=1)\n",
        "\n",
        "#compute the confusion matrix\n",
        "cm=confusion_matrix(y_true,y_pred_classes)\n",
        "\n",
        "#plot the confusion matrix using seaborn's heatmap\n",
        "plt.figure(figsize=(10,0))\n",
        "sns.heatmap(cm,annot=True, fmt='d',cmap='Blues',xticklables=labels,yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44a3f72d-1d76-4d98-9f03-1f8293ed6ad6",
      "metadata": {
        "id": "44a3f72d-1d76-4d98-9f03-1f8293ed6ad6"
      },
      "source": [
        "### 5. Hyperparameter tunning and regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6140057-ce25-4e97-ae7b-81a47a30bebc",
      "metadata": {
        "id": "e6140057-ce25-4e97-ae7b-81a47a30bebc"
      },
      "source": [
        "When your code is ready and fully functional, try several changes in the hyperparameters and see how they influence the testing metrics. Try changes in the network structure. You can also try adding regularization techniques such as L1, L2, and Dropout. Based on the development of training and validation loss, try to identify overfitting and avoid it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f4b10b-7487-45f4-8702-267715e4041c",
      "metadata": {
        "id": "f1f4b10b-7487-45f4-8702-267715e4041c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}